{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMqC2CA1MhqksHZFEhLpA6r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owaisali246/pytorch/blob/main/Pytorch_code_camp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YT-time: 1:22:00"
      ],
      "metadata": {
        "id": "w-kcXE4y1T4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/amitness/colab-connect.git"
      ],
      "metadata": {
        "id": "PSBUaF_460Ts",
        "outputId": "597c998a-d954-43b0-f127-a97dc06f47ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/amitness/colab-connect.git\n",
            "  Cloning https://github.com/amitness/colab-connect.git to /tmp/pip-req-build-11pzax21\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/amitness/colab-connect.git /tmp/pip-req-build-11pzax21\n",
            "  Resolved https://github.com/amitness/colab-connect.git to commit a2e2c7901fc57e4d833645925243582081ee00e8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: colabconnect\n",
            "  Building wheel for colabconnect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colabconnect: filename=colabconnect-0.0.8-py3-none-any.whl size=4901 sha256=c198428088d7046418add2c509d1b47db173191190948be55994f264524024bc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-16k1imu4/wheels/a9/e9/4c/3d90592a37b038bc977fc85ed256da2bc4a8f8b34930509307\n",
            "Successfully built colabconnect\n",
            "Installing collected packages: colabconnect\n",
            "Successfully installed colabconnect-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from colabconnect import colabconnect\n",
        "\n",
        "colabconnect()"
      ],
      "metadata": {
        "id": "8g3uh_0q67I9",
        "outputId": "0eb1f7ef-59a4-48ce-a845-30b984cee0ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Ran: ln -s /content/drive/MyDrive/colab/ /\n",
            "Installing python libraries...\n",
            "Ran: pip3 install --user flake8 black ipywidgets twine\n",
            "Ran: pip3 install -U ipykernel\n",
            "Ran: apt install htop -y\n",
            "Installing vscode-cli...\n",
            "Ran: curl -Lk https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64 --output vscode_cli.tar.gz\n",
            "Ran: tar -xf vscode_cli.tar.gz\n",
            "Starting the tunnel\n",
            "To grant access to the server, please log into https://github.com/login/device and use code FDB2-BBAE\n",
            "Starting the tunnel\n",
            "- Ready!\n",
            "- Open VSCode on your laptop and open the command prompt\n",
            "- Select: 'Remote-Tunnels: Connect to Tunnel' to connect to colab\n",
            "Logs:\n",
            "\n",
            "[2025-09-07 16:10:16] info [tunnels::connections::relay_tunnel_host] Opened new client on channel 2\n",
            "[2025-09-07 16:10:16] info [russh::server] wrote id\n",
            "[2025-09-07 16:10:17] info [russh::server] read other id\n",
            "[2025-09-07 16:10:17] info [russh::server] session is running\n",
            "[2025-09-07 16:10:18] info [rpc.0] Checking /root/.vscode/cli/servers/Stable-c306e94f98122556ca081f527b466015e1bc37b0/log.txt and /root/.vscode/cli/servers/Stable-c306e94f98122556ca081f527b466015e1bc37b0/pid.txt for a running server...\n",
            "[2025-09-07 16:10:19] info [rpc.0] Downloading Visual Studio Code server -> /tmp/.tmpXh2HRW/vscode-server-linux-x64.tar.gz\n",
            "[2025-09-07 16:10:26] info [rpc.0] Starting server...\n",
            "[2025-09-07 16:10:26] info [rpc.0] Server started\n",
            "[2025-09-07 16:10:42] info [tunnels::connections::relay_tunnel_host] Opened new client on channel 3\n",
            "[2025-09-07 16:10:42] info [russh::server] wrote id\n",
            "[2025-09-07 16:10:42] info [tunnels::connections::relay_tunnel_host] Opened new client on channel 4\n",
            "[2025-09-07 16:10:42] info [russh::server] wrote id\n",
            "[2025-09-07 16:10:42] info [russh::server] read other id\n",
            "[2025-09-07 16:10:42] info [russh::server] session is running\n",
            "[2025-09-07 16:10:42] info [russh::server] read other id\n",
            "[2025-09-07 16:10:42] info [russh::server] session is running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKd9f2TfpZkb"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9p4CdWvtniB",
        "outputId": "fd0d5a6e-8c98-4588-ddd1-965a2ed90448"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n",
            "Sun Sep  7 15:41:33 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = 45"
      ],
      "metadata": {
        "id": "9P6QVCt713qp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}